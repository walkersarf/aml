{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Anti Money Laundering Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-10-07T05:03:44.040372Z",
     "iopub.status.busy": "2023-10-07T05:03:44.039793Z",
     "iopub.status.idle": "2023-10-07T05:03:58.147392Z",
     "shell.execute_reply": "2023-10-07T05:03:58.146038Z",
     "shell.execute_reply.started": "2023-10-07T05:03:44.040343Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "from typing import Callable, Optional\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from torch_geometric.data import (\n",
    "    Data,\n",
    "    InMemoryDataset\n",
    ")\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "path = 'HI-Small_Trans.csv'\n",
    "df = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:33:22.849494Z",
     "iopub.status.busy": "2023-10-07T05:33:22.849049Z",
     "iopub.status.idle": "2023-10-07T05:33:22.867501Z",
     "shell.execute_reply": "2023-10-07T05:33:22.866198Z",
     "shell.execute_reply.started": "2023-10-07T05:33:22.849448Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp  From Bank    Account  To Bank  Account.1  \\\n",
      "0  2022/09/01 00:20         10  8000EBD30       10  8000EBD30   \n",
      "1  2022/09/01 00:20       3208  8000F4580        1  8000F5340   \n",
      "2  2022/09/01 00:00       3209  8000F4670     3209  8000F4670   \n",
      "3  2022/09/01 00:02         12  8000F5030       12  8000F5030   \n",
      "4  2022/09/01 00:06         10  8000F5200       10  8000F5200   \n",
      "\n",
      "   Amount Received Receiving Currency  Amount Paid Payment Currency  \\\n",
      "0          3697.34          US Dollar      3697.34        US Dollar   \n",
      "1             0.01          US Dollar         0.01        US Dollar   \n",
      "2         14675.57          US Dollar     14675.57        US Dollar   \n",
      "3          2806.97          US Dollar      2806.97        US Dollar   \n",
      "4         36682.97          US Dollar     36682.97        US Dollar   \n",
      "\n",
      "  Payment Format  Is Laundering  \n",
      "0   Reinvestment              0  \n",
      "1         Cheque              0  \n",
      "2   Reinvestment              0  \n",
      "3   Reinvestment              0  \n",
      "4   Reinvestment              0  \n"
     ]
    }
   ],
   "source": [
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:36:52.790986Z",
     "iopub.status.busy": "2023-10-07T05:36:52.790429Z",
     "iopub.status.idle": "2023-10-07T05:36:52.797831Z",
     "shell.execute_reply": "2023-10-07T05:36:52.796721Z",
     "shell.execute_reply.started": "2023-10-07T05:36:52.790952Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp              object\n",
      "From Bank               int64\n",
      "Account                object\n",
      "To Bank                 int64\n",
      "Account.1              object\n",
      "Amount Received       float64\n",
      "Receiving Currency     object\n",
      "Amount Paid           float64\n",
      "Payment Currency       object\n",
      "Payment Format         object\n",
      "Is Laundering           int64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:40:11.526713Z",
     "iopub.status.busy": "2023-10-07T05:40:11.526397Z",
     "iopub.status.idle": "2023-10-07T05:40:12.913554Z",
     "shell.execute_reply": "2023-10-07T05:40:12.912335Z",
     "shell.execute_reply.started": "2023-10-07T05:40:11.526687Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timestamp             0\n",
      "From Bank             0\n",
      "Account               0\n",
      "To Bank               0\n",
      "Account.1             0\n",
      "Amount Received       0\n",
      "Receiving Currency    0\n",
      "Amount Paid           0\n",
      "Payment Currency      0\n",
      "Payment Format        0\n",
      "Is Laundering         0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:11.423289Z",
     "iopub.status.busy": "2023-10-07T05:53:11.422843Z",
     "iopub.status.idle": "2023-10-07T05:53:11.432504Z",
     "shell.execute_reply": "2023-10-07T05:53:11.431355Z",
     "shell.execute_reply.started": "2023-10-07T05:53:11.423245Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "def df_label_encoder(df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "def preprocess(df):\n",
    "        # Label the 'Payment Format', 'Payment Currency', 'Receiving Currency' by classes with sklearn LabelEncoder\n",
    "        df = df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        # Transform the Timestamp with min max normalization.  \n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "        # Create unique ID for each account by adding bank code with account number.  \n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        # Create receiving_df with the information of receiving accounts, received amount and currency\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        # Create paying_df with the information of payer accounts, paid amount and currency\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        # Create a list of currency used among all transactions\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:53:15.266963Z",
     "iopub.status.busy": "2023-10-07T05:53:15.266592Z",
     "iopub.status.idle": "2023-10-07T05:53:56.218064Z",
     "shell.execute_reply": "2023-10-07T05:53:56.216975Z",
     "shell.execute_reply.started": "2023-10-07T05:53:15.266935Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  From Bank          Account  To Bank        Account.1  \\\n",
      "4278714   0.456320      10057  10057_803A115E0    29467  29467_803E020C0   \n",
      "2798190   0.285018      10057  10057_803A115E0    29467  29467_803E020C0   \n",
      "2798191   0.284233      10057  10057_803A115E0    29467  29467_803E020C0   \n",
      "3918769   0.417079      10057  10057_803A115E0    29467  29467_803E020C0   \n",
      "213094    0.000746      10057  10057_803A115E0    10057  10057_803A115E0   \n",
      "\n",
      "         Amount Received  Receiving Currency  Amount Paid  Payment Currency  \\\n",
      "4278714        787197.11                  13    787197.11                13   \n",
      "2798190        787197.11                  13    787197.11                13   \n",
      "2798191        681262.19                  13    681262.19                13   \n",
      "3918769        681262.19                  13    681262.19                13   \n",
      "213094         146954.27                  13    146954.27                13   \n",
      "\n",
      "         Payment Format  Is Laundering  \n",
      "4278714               3              0  \n",
      "2798190               3              0  \n",
      "2798191               4              0  \n",
      "3918769               4              0  \n",
      "213094                5              0  \n"
     ]
    }
   ],
   "source": [
    "df, receiving_df, paying_df, currency_ls = preprocess(df = df)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:25.918744Z",
     "iopub.status.busy": "2023-10-07T05:57:25.918280Z",
     "iopub.status.idle": "2023-10-07T05:57:25.929797Z",
     "shell.execute_reply": "2023-10-07T05:57:25.928625Z",
     "shell.execute_reply.started": "2023-10-07T05:57:25.918708Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Account  Amount Received  Receiving Currency\n",
      "4278714  29467_803E020C0        787197.11                  13\n",
      "2798190  29467_803E020C0        787197.11                  13\n",
      "2798191  29467_803E020C0        681262.19                  13\n",
      "3918769  29467_803E020C0        681262.19                  13\n",
      "213094   10057_803A115E0        146954.27                  13\n",
      "                 Account  Amount Paid  Payment Currency\n",
      "4278714  10057_803A115E0    787197.11                13\n",
      "2798190  10057_803A115E0    787197.11                13\n",
      "2798191  10057_803A115E0    681262.19                13\n",
      "3918769  10057_803A115E0    681262.19                13\n",
      "213094   10057_803A115E0    146954.27                13\n"
     ]
    }
   ],
   "source": [
    "print(receiving_df.head())\n",
    "print(paying_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:28.907031Z",
     "iopub.status.busy": "2023-10-07T05:57:28.906667Z",
     "iopub.status.idle": "2023-10-07T05:57:28.913761Z",
     "shell.execute_reply": "2023-10-07T05:57:28.912327Z",
     "shell.execute_reply.started": "2023-10-07T05:57:28.907004Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[np.int64(0), np.int64(1), np.int64(2), np.int64(3), np.int64(4), np.int64(5), np.int64(6), np.int64(7), np.int64(8), np.int64(9), np.int64(10), np.int64(11), np.int64(12), np.int64(13), np.int64(14)]\n"
     ]
    }
   ],
   "source": [
    "print(currency_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:31.850839Z",
     "iopub.status.busy": "2023-10-07T05:57:31.850459Z",
     "iopub.status.idle": "2023-10-07T05:57:31.858990Z",
     "shell.execute_reply": "2023-10-07T05:57:31.857826Z",
     "shell.execute_reply.started": "2023-10-07T05:57:31.850810Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# We would like to extract all unique accounts from payer and receiver as node of our graph. It includes the unique account ID, Bank code and the label of 'Is Laundering'.  \n",
    "# In this section, we consider both payer and receiver involved in a illicit transaction as suspicious accounts, we will label both accounts with 'Is Laundering' == 1.\n",
    "def get_all_account(df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:34.379521Z",
     "iopub.status.busy": "2023-10-07T05:57:34.378456Z",
     "iopub.status.idle": "2023-10-07T05:57:41.317058Z",
     "shell.execute_reply": "2023-10-07T05:57:41.316062Z",
     "shell.execute_reply.started": "2023-10-07T05:57:34.379481Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Account   Bank  Is Laundering\n",
      "0  10057_803A115E0  10057              0\n",
      "1  10057_803AA8E90  10057              0\n",
      "2  10057_803AAB430  10057              0\n",
      "3  10057_803AACE20  10057              0\n",
      "4  10057_803AB4F70  10057              0\n"
     ]
    }
   ],
   "source": [
    "accounts = get_all_account(df)\n",
    "print(accounts.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:43.694369Z",
     "iopub.status.busy": "2023-10-07T05:57:43.693958Z",
     "iopub.status.idle": "2023-10-07T05:57:43.701141Z",
     "shell.execute_reply": "2023-10-07T05:57:43.699901Z",
     "shell.execute_reply.started": "2023-10-07T05:57:43.694334Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# For node features, we would like to aggregate the mean of paid and received amount with different types of currency as the new features of each node. \n",
    "def paid_currency_aggregate(currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "def received_currency_aggregate(currency_ls, receiving_df, accounts):\n",
    "    for i in currency_ls:\n",
    "        temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "        accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "    accounts = accounts.fillna(0)\n",
    "    return accounts\n",
    "# Now we can define the node attributes by the bank code and the mean of paid and received amount with different types of currency.\n",
    "def get_node_attr(currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = df_label_encoder(node_df,['Bank'])\n",
    "        return node_df, node_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:57:48.258031Z",
     "iopub.status.busy": "2023-10-07T05:57:48.257639Z",
     "iopub.status.idle": "2023-10-07T05:57:56.275657Z",
     "shell.execute_reply": "2023-10-07T05:57:56.274417Z",
     "shell.execute_reply.started": "2023-10-07T05:57:48.257999Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Bank  avg paid 0  avg paid 1  avg paid 2  avg paid 3  avg paid 4  \\\n",
      "0     2         0.0         0.0         0.0         0.0         0.0   \n",
      "1     2         0.0         0.0         0.0         0.0         0.0   \n",
      "2     2         0.0         0.0         0.0         0.0         0.0   \n",
      "3     2         0.0         0.0         0.0         0.0         0.0   \n",
      "4     2         0.0         0.0         0.0         0.0         0.0   \n",
      "\n",
      "   avg paid 5  avg paid 6  avg paid 7  avg paid 8  avg paid 9  avg paid 10  \\\n",
      "0         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "1         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "2         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "3         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "4         0.0         0.0         0.0         0.0         0.0          0.0   \n",
      "\n",
      "   avg paid 11   avg paid 12  avg paid 13  avg paid 14  avg received 0  \\\n",
      "0          0.0   1922.000000          0.0          0.0             0.0   \n",
      "1          0.0    480.223333          0.0          0.0             0.0   \n",
      "2          0.0  14675.570000          0.0          0.0             0.0   \n",
      "3          0.0  37340.843333          0.0          0.0             0.0   \n",
      "4          0.0  49649.409677          0.0          0.0             0.0   \n",
      "\n",
      "   avg received 1  avg received 2  avg received 3  avg received 4  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 5  avg received 6  avg received 7  avg received 8  \\\n",
      "0             0.0             0.0             0.0             0.0   \n",
      "1             0.0             0.0             0.0             0.0   \n",
      "2             0.0             0.0             0.0             0.0   \n",
      "3             0.0             0.0             0.0             0.0   \n",
      "4             0.0             0.0             0.0             0.0   \n",
      "\n",
      "   avg received 9  avg received 10  avg received 11  avg received 12  \\\n",
      "0             0.0              0.0              0.0       330.166429   \n",
      "1             0.0              0.0              0.0       119.992000   \n",
      "2             0.0              0.0              0.0     14675.570000   \n",
      "3             0.0              0.0              0.0       756.486190   \n",
      "4             0.0              0.0              0.0      3120.573333   \n",
      "\n",
      "   avg received 13  avg received 14  \n",
      "0              0.0              0.0  \n",
      "1              0.0              0.0  \n",
      "2              0.0              0.0  \n",
      "3              0.0              0.0  \n",
      "4              0.0              0.0  \n"
     ]
    }
   ],
   "source": [
    "node_df, node_label = get_node_attr(currency_ls, paying_df,receiving_df, accounts)\n",
    "print(node_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Edge\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:06.006625Z",
     "iopub.status.busy": "2023-10-07T05:58:06.006227Z",
     "iopub.status.idle": "2023-10-07T05:58:06.015211Z",
     "shell.execute_reply": "2023-10-07T05:58:06.014356Z",
     "shell.execute_reply.started": "2023-10-07T05:58:06.006594Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# In terms of edge features, we would like to conside each transcation as edges.  \n",
    "# For edge index, we replace all account with index and stack into a list with size of [2, num of transcation]  \n",
    "# For edge attributes, we used 'Timestamp', 'Amount Received', 'Receiving Currency', 'Amount Paid', 'Payment Currency' and 'Payment Format'\n",
    "\n",
    "def get_edge_df(accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "        df = df.drop(['Account', 'Account.1', 'From Bank', 'To Bank'], axis=1)\n",
    "\n",
    "        edge_index = torch.stack([torch.from_numpy(df['From'].values), torch.from_numpy(df['To'].values)], dim=0)\n",
    "\n",
    "        df = df.drop(['Is Laundering', 'From', 'To'], axis=1)\n",
    "        edge_attr = df  # for visualization\n",
    "        return edge_attr, edge_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T06:00:02.820037Z",
     "iopub.status.busy": "2023-10-07T06:00:02.819644Z",
     "iopub.status.idle": "2023-10-07T06:00:07.880960Z",
     "shell.execute_reply": "2023-10-07T06:00:07.879754Z",
     "shell.execute_reply.started": "2023-10-07T06:00:02.820005Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         Timestamp  Amount Received  Receiving Currency  Amount Paid  \\\n",
      "4278714   0.456320        787197.11                  13    787197.11   \n",
      "2798190   0.285018        787197.11                  13    787197.11   \n",
      "2798191   0.284233        681262.19                  13    681262.19   \n",
      "3918769   0.417079        681262.19                  13    681262.19   \n",
      "213094    0.000746        146954.27                  13    146954.27   \n",
      "\n",
      "         Payment Currency  Payment Format  \n",
      "4278714                13               3  \n",
      "2798190                13               3  \n",
      "2798191                13               4  \n",
      "3918769                13               4  \n",
      "213094                 13               5  \n"
     ]
    }
   ],
   "source": [
    "edge_attr, edge_index = get_edge_df(accounts, df)\n",
    "print(edge_attr.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-07T05:58:16.265617Z",
     "iopub.status.busy": "2023-10-07T05:58:16.265045Z",
     "iopub.status.idle": "2023-10-07T05:58:16.274597Z",
     "shell.execute_reply": "2023-10-07T05:58:16.273471Z",
     "shell.execute_reply.started": "2023-10-07T05:58:16.265571Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[     0,      0,      0,  ..., 496997, 496997, 496998],\n",
      "        [299458, 299458, 299458,  ..., 496997, 496997, 496998]])\n"
     ]
    }
   ],
   "source": [
    "print(edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EvolveGCN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class EvolveGCNH(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, hidden_channels):\n",
    "        super(EvolveGCNH, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.hidden_channels = hidden_channels\n",
    "        self.rnn = nn.GRUCell(in_channels, hidden_channels)\n",
    "        self.gcn = GCNConv(hidden_channels, out_channels)\n",
    "        self.hidden_state = None\n",
    "\n",
    "    def forward(self, x, edge_index, edge_attr=None):\n",
    "        if self.hidden_state is None or self.hidden_state.size(0) != x.size(0):\n",
    "            self.hidden_state = x.new_zeros(x.size(0), self.hidden_channels)\n",
    "        self.hidden_state = self.hidden_state.detach()\n",
    "        self.hidden_state = self.rnn(x, self.hidden_state)\n",
    "        x = self.gcn(self.hidden_state, edge_index)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyG InMemoryDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "class AMLtoGraph(InMemoryDataset):\n",
    "\n",
    "    def __init__(self, root: str, edge_window_size: int = 10,\n",
    "                 transform: Optional[Callable] = None,\n",
    "                 pre_transform: Optional[Callable] = None):\n",
    "        self.edge_window_size = edge_window_size\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        self.data, self.slices = torch.load(self.processed_paths[0])\n",
    "\n",
    "    @property\n",
    "    def raw_file_names(self) -> str:\n",
    "        return 'HI-Small_Trans.csv'\n",
    "\n",
    "    @property\n",
    "    def processed_file_names(self) -> str:\n",
    "        return 'data.pt'\n",
    "\n",
    "    @property\n",
    "    def num_nodes(self) -> int:\n",
    "        return self._data.edge_index.max().item() + 1\n",
    "\n",
    "    def df_label_encoder(self, df, columns):\n",
    "        le = preprocessing.LabelEncoder()\n",
    "        for i in columns:\n",
    "            df[i] = le.fit_transform(df[i].astype(str))\n",
    "        return df\n",
    "\n",
    "\n",
    "    def preprocess(self, df):\n",
    "        df = self.df_label_encoder(df,['Payment Format', 'Payment Currency', 'Receiving Currency'])\n",
    "        df['Timestamp'] = pd.to_datetime(df['Timestamp'])\n",
    "        df['Timestamp'] = df['Timestamp'].apply(lambda x: x.value)\n",
    "        df['Timestamp'] = (df['Timestamp']-df['Timestamp'].min())/(df['Timestamp'].max()-df['Timestamp'].min())\n",
    "\n",
    "        df['Account'] = df['From Bank'].astype(str) + '_' + df['Account']\n",
    "        df['Account.1'] = df['To Bank'].astype(str) + '_' + df['Account.1']\n",
    "        df = df.sort_values(by=['Account'])\n",
    "        receiving_df = df[['Account.1', 'Amount Received', 'Receiving Currency']]\n",
    "        paying_df = df[['Account', 'Amount Paid', 'Payment Currency']]\n",
    "        receiving_df = receiving_df.rename({'Account.1': 'Account'}, axis=1)\n",
    "        currency_ls = sorted(df['Receiving Currency'].unique())\n",
    "\n",
    "        return df, receiving_df, paying_df, currency_ls\n",
    "\n",
    "    def get_all_account(self, df):\n",
    "        ldf = df[['Account', 'From Bank']]\n",
    "        rdf = df[['Account.1', 'To Bank']]\n",
    "        suspicious = df[df['Is Laundering']==1]\n",
    "        s1 = suspicious[['Account', 'Is Laundering']]\n",
    "        s2 = suspicious[['Account.1', 'Is Laundering']]\n",
    "        s2 = s2.rename({'Account.1': 'Account'}, axis=1)\n",
    "        suspicious = pd.concat([s1, s2], join='outer')\n",
    "        suspicious = suspicious.drop_duplicates()\n",
    "\n",
    "        ldf = ldf.rename({'From Bank': 'Bank'}, axis=1)\n",
    "        rdf = rdf.rename({'Account.1': 'Account', 'To Bank': 'Bank'}, axis=1)\n",
    "        df = pd.concat([ldf, rdf], join='outer')\n",
    "        df = df.drop_duplicates()\n",
    "\n",
    "        df['Is Laundering'] = 0\n",
    "        df.set_index('Account', inplace=True)\n",
    "        df.update(suspicious.set_index('Account'))\n",
    "        df = df.reset_index()\n",
    "        return df\n",
    "    \n",
    "    def paid_currency_aggregate(self, currency_ls, paying_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = paying_df[paying_df['Payment Currency'] == i]\n",
    "            accounts['avg paid '+str(i)] = temp['Amount Paid'].groupby(temp['Account']).transform('mean')\n",
    "        return accounts\n",
    "\n",
    "    def received_currency_aggregate(self, currency_ls, receiving_df, accounts):\n",
    "        for i in currency_ls:\n",
    "            temp = receiving_df[receiving_df['Receiving Currency'] == i]\n",
    "            accounts['avg received '+str(i)] = temp['Amount Received'].groupby(temp['Account']).transform('mean')\n",
    "        accounts = accounts.fillna(0)\n",
    "        return accounts\n",
    "\n",
    "    def get_edge_df(self, accounts, df):\n",
    "        accounts = accounts.reset_index(drop=True)\n",
    "        accounts['ID'] = accounts.index\n",
    "        mapping_dict = dict(zip(accounts['Account'], accounts['ID']))\n",
    "        \n",
    "        df['From'] = df['Account'].map(mapping_dict)\n",
    "        df['To'] = df['Account.1'].map(mapping_dict)\n",
    "\n",
    "        edge_index = torch.tensor(\n",
    "            [df['From'].values, df['To'].values],\n",
    "            dtype=torch.long\n",
    "        )\n",
    "        \n",
    "        df = df.drop(['From', 'To', 'Account', 'Account.1'], axis=1)\n",
    "        edge_attr = torch.tensor(df.values, dtype=torch.float)\n",
    "\n",
    "        return edge_attr, edge_index\n",
    "\n",
    "\n",
    "    def get_node_attr(self, currency_ls, paying_df,receiving_df, accounts):\n",
    "        node_df = self.paid_currency_aggregate(currency_ls, paying_df, accounts)\n",
    "        node_df = self.received_currency_aggregate(currency_ls, receiving_df, node_df)\n",
    "        node_label = torch.from_numpy(node_df['Is Laundering'].values).to(torch.float)\n",
    "        node_df = node_df.drop(['Account', 'Is Laundering'], axis=1)\n",
    "        node_df = self.df_label_encoder(node_df,['Bank'])\n",
    "        node_df = torch.from_numpy(node_df.values).to(torch.float)\n",
    "        return node_df, node_label\n",
    "\n",
    "    def process(self):\n",
    "        df = pd.read_csv(self.raw_paths[0])\n",
    "        df, receiving_df, paying_df, currency_ls = self.preprocess(df)\n",
    "        accounts = self.get_all_account(df)\n",
    "        node_attr, node_label = self.get_node_attr(currency_ls, paying_df, receiving_df, accounts)\n",
    "        edge_attr, edge_index = self.get_edge_df(accounts, df)\n",
    "\n",
    "        data = Data(\n",
    "            x=node_attr,\n",
    "            edge_index=edge_index,\n",
    "            edge_attr=edge_attr,\n",
    "            y=node_label\n",
    "        )\n",
    "\n",
    "        # Add train/val/test masks\n",
    "        num_nodes = data.x.size(0)\n",
    "        data.train_mask = torch.rand(num_nodes) < 0.8\n",
    "        data.val_mask = ~data.train_mask\n",
    "\n",
    "        # Save processed data\n",
    "        data_list = [data]\n",
    "        data, slices = self.collate(data_list)\n",
    "        torch.save((data, slices), self.processed_paths[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\souro\\AppData\\Local\\Temp\\ipykernel_25332\\1868873253.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  self.data, self.slices = torch.load(self.processed_paths[0])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 723.1804\n",
      "Epoch 2, Loss: 434.7213\n",
      "Epoch 3, Loss: 313.7039\n",
      "Epoch 4, Loss: 247.0510\n",
      "Epoch 5, Loss: 203.8094\n",
      "Epoch 05/20, Loss: 203.8094, Val Accuracy: 0.9709\n",
      "Epoch 6, Loss: 172.6424\n",
      "Epoch 7, Loss: 153.6973\n",
      "Epoch 8, Loss: 139.7013\n",
      "Epoch 9, Loss: 129.3076\n",
      "Epoch 10, Loss: 117.6553\n",
      "Epoch 10/20, Loss: 117.6553, Val Accuracy: 0.9927\n",
      "Epoch 11, Loss: 110.6357\n",
      "Epoch 12, Loss: 105.5695\n",
      "Epoch 13, Loss: 101.1098\n",
      "Epoch 14, Loss: 97.1739\n",
      "Epoch 15, Loss: 93.3803\n",
      "Epoch 15/20, Loss: 93.3803, Val Accuracy: 0.9928\n",
      "Epoch 16, Loss: 90.2055\n",
      "Epoch 17, Loss: 87.2068\n",
      "Epoch 18, Loss: 84.3601\n",
      "Epoch 19, Loss: 81.7867\n",
      "Epoch 20, Loss: 79.4491\n",
      "Epoch 20/20, Loss: 79.4491, Val Accuracy: 0.9928\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.loader import NeighborLoader\n",
    "from torch_geometric.transforms import RandomNodeSplit\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Load dataset\n",
    "dataset = AMLtoGraph('')\n",
    "data = dataset[0]\n",
    "data = RandomNodeSplit(split='train_rest', num_val=0.1)(data)\n",
    "\n",
    "# Data loaders\n",
    "train_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.train_mask,\n",
    ")\n",
    "\n",
    "val_loader = NeighborLoader(\n",
    "    data,\n",
    "    num_neighbors=[30] * 2,\n",
    "    batch_size=256,\n",
    "    input_nodes=data.val_mask,\n",
    ")\n",
    "\n",
    "model = EvolveGCNH(\n",
    "    in_channels=data.num_features,  # Number of input features per node\n",
    "    out_channels=1,                 # Binary classification (1 output feature)\n",
    "    hidden_channels=16              # Number of hidden units\n",
    ").to(device)\n",
    "\n",
    "\n",
    "criterion = torch.nn.BCELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
    "epochs = 20\n",
    "\n",
    "for epoch in range(20):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for batch in train_loader:\n",
    "        batch.to(device)\n",
    "        pred = model(batch.x, batch.edge_index)\n",
    "        pred = torch.sigmoid(pred)\n",
    "        loss = criterion(pred, batch.y.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch + 1}, Loss: {total_loss:.4f}\")\n",
    "\n",
    "\n",
    "    if (epoch + 1) % 5 == 0 or epoch == epochs - 1:\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in val_loader:\n",
    "                batch.to(device)\n",
    "                pred = model(batch.x, batch.edge_index, batch.edge_attr)\n",
    "                pred = torch.sigmoid(pred).squeeze()\n",
    "                pred_labels = (pred > 0.5).float()\n",
    "                ground_truth = batch.y\n",
    "\n",
    "                correct += (pred_labels == ground_truth).sum().item()\n",
    "                total += len(ground_truth)\n",
    "\n",
    "        accuracy = correct / total\n",
    "        print(f\"Epoch {epoch + 1:02d}/{epochs}, Loss: {total_loss:.4f}, Val Accuracy: {accuracy:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
